{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Random Forest"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Imports**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from io import StringIO\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt \n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from pickle import dump\n",
                "from sklearn import tree\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Carga de datos**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "url=\"https://raw.githubusercontent.com/4GeeksAcademy/decision-tree-project-tutorial/main/diabetes.csv\"\n",
                "\n",
                "data=pd.read_csv(url)\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Realizamos un EDA completo**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tenemos 8 variables (todas numéricas) y la variable objetivo (1: diabetes 0: No diabetes), con un total de **768 pacientes**:\n",
                "\n",
                "* **Pregnancies:** Número de embarazos del paciente (numérico)\n",
                "* **Glucose:** Concentración de glucosa en plasma a las 2 horas de un test de tolerancia oral a la glucosa (numérico)\n",
                "* **BloodPressure:** Presión arterial diastólica (medida en mm Hg) (numérico)\n",
                "* **SkinThickness:** Grosor del pliegue cutáneo del tríceps (medida en mm) (numérico)\n",
                "* **Insulin:** Insulina sérica de 2 horas (medida en mu U/ml) (numérico)\n",
                "* **BMI:** Índice de masa corporal (numérico)\n",
                "* **DiabetesPedigreeFunction:** Función de pedigrí de diabetes (numérico)\n",
                "* **Age:** Edad del paciente (numérico)\n",
                "* **Outcome:** Variable **objetivo** de clase (0 o 1), siendo 0 negativo en diabetes y 1, positivo (numérico)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos a buscar y eliminar los duplicados y los nulos: No existen duplicados ni nulos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(data.duplicated().sum())\n",
                "print(data.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Exploramos las variables, distribuciones y datos atípicos:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "j=0\n",
                "fig, axis= plt.subplots(2,4,figsize=(10,4))\n",
                "for i in data.columns.drop(\"Outcome\"):\n",
                "\n",
                "    axis[0,j].plot(data[i])\n",
                "    sns.boxplot(data=data,x=i,ax=axis[1,j])\n",
                "    j+=1\n",
                "    if j==4: \n",
                "        j=0\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        if i!=data.columns.drop(\"Outcome\")[len(data.columns)-2]:\n",
                "            fig, axis= plt.subplots(2,4,figsize=(10,4))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Limpieza de datos atipicos: A simple vista, vemos algunos datos atípicos que probablemente sean errores en la medición: Glucosa 0, BMI 0, Blood Pressure 0. \n",
                "Vamos a ver si son los mismos pacientes para eliminarlos directamente, sino esos valores erróneos los llevaremos a la media.\n",
                "\n",
                "También vamos a limpiar los datos de atípicos, intentando no disminuir demasiado el dataset ya que la cantidad de datos no es muy elevada:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Gl0=data[data[\"Glucose\"]==0].index\n",
                "BMI0=data[data[\"BMI\"]==0].index\n",
                "BP0=data[data[\"BloodPressure\"]==0].index\n",
                "\n",
                "union0=[x for x in Gl0 if x in BMI0 and x in BP0]\n",
                "\n",
                "print(f\"El número de pacientes con 0 en Glucosa es: {len(Gl0)}\\nEl número de pacientes con 0 en BMI es:{len(BMI0)}\\nEl número de pacientes con 0 en BP0 es: {len(BP0)} \\nEl número de pacientes con todos los indicadores en 0 es: {len(union0)} \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hemos comprobado que los valores nulos en las variables Glucose, BMI y BloodPressure no coinciden en los tres casos, por tanto, alguna de las variables sí se está tomando correctamente en esos casos. Nos llevamos esos atípicos, junto con el resto a la media."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Definimos una función para llevar los atípicos a la media:\n",
                "\n",
                "def out_mean(var,inf=5,sup=95):\n",
                "    \n",
                "    lim_inf = np.percentile(var, inf)\n",
                "    lim_sup = np.percentile(var, sup)\n",
                "    outliers = (var < lim_inf) | (var > lim_sup)\n",
                "    var_clean=var.copy()\n",
                "    var_clean[outliers]=np.mean(var[~outliers])\n",
                "    return var_clean    \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos a limpiar todas las variables:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_clean=pd.DataFrame()\n",
                "for i in data.columns.drop(\"Outcome\"):\n",
                "    data_clean[i]=out_mean(data[i])\n",
                "    fig, axis = plt.subplots(1,2,figsize=(10,4))\n",
                "    sns.boxplot(x=data[i],ax=axis[0])\n",
                "    x=np.percentile(data[i],75)\n",
                "    sns.boxplot(x=data_clean[i],ax=axis[1])\n",
                "    axis[0].text(x,0.7,round(data[i].describe(),2),fontsize=10, ha='right', va='top')\n",
                "    axis[1].text(x,0.7,round(data_clean[i].describe(),2),fontsize=10, ha='right', va='top')\n",
                "data_clean[\"Outcome\"]=data[\"Outcome\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Comprobamos la correlación con la variable objetivo del dataset limpio y con atípicos:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "j=0\n",
                "col=\"blue\"\n",
                "fig, axis= plt.subplots(1,4,figsize=(10,4))\n",
                "for i in data.columns.drop(\"Outcome\"):\n",
                "\n",
                "    sns.regplot(data=data,x=i,y=\"Outcome\",ax=axis[j],color=col)\n",
                "    sns.regplot(data=data_clean,x=i,y=\"Outcome\",ax=axis[j+1],color=col)\n",
                "    x1=np.percentile(data[i],85)\n",
                "    x2=np.percentile(data_clean[i],85)\n",
                "    axis[j].text(x1,0.8,\"corr=\" + str(round(data[i].corr(data[\"Outcome\"]),2)),fontsize=10, ha='right', va='top')\n",
                "    axis[j+1].text(x2,0.8,\"corr=\" + str(round(data_clean[i].corr(data_clean[\"Outcome\"]),2)),fontsize=10, ha='right', va='top')\n",
                "    j+=2\n",
                "    col=\"red\"\n",
                "    if j==4: \n",
                "        j=0\n",
                "        col=\"blue\"\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        if i!=data.columns.drop(\"Outcome\")[len(data.columns)-2]:\n",
                "            fig, axis= plt.subplots(1,4,figsize=(10,4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como podemos ver, con la limpieza hemos disminuido la amplitud del intervalo de confianza en todos los casos.\n",
                "\n",
                "Si quisieramos disminuir el numero de caracteristicas podríamos empezar con las variables: Insulin y Skinthickness que tienen una correlación baja con la variable objetivo. Más adelante probaremos a ver si mejora el modelo.\n",
                "\n",
                "Como estamos con un random forest, no vamos a normalizar las variables."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Realizamos un parallel coordinates como paso final para visualizar todas las variables predictoras frente a la variable objetivo:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.plotting.parallel_coordinates(data_clean, \"Outcome\", color = (\"#E58139\", \"#39E581\"))\n",
                "plt.xticks(rotation=45)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos cómo la variable **Glucose** es la que más impacto tiene y la variable **Age** también puede tener impacto. Junto con las regresiones concluimos que esas variables y **BMI** son las que **mayor impacto** parecen tener en la Diabetes en este data set.\n",
                "\n",
                "También se observa fácilmente en este gráfico que las variables **SkinThickness**, **Insulin** y **DiabetesPedigreeFunction** tienen una **correlación muy baja** con el objetivo.\n",
                "\n",
                "Vamos a realizar un random forest para observar los resultados, con el data set completo, en primer lugar:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Separamos las muestras de entrenamiento y test:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X=data_clean.drop(\"Outcome\",axis=1,inplace=False).copy()\n",
                "y=data_clean[\"Outcome\"].copy()\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
                "\n",
                "print(X_train.info(),y_train.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Inicialización y entrenamiento del modelo**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "model = DecisionTreeClassifier(random_state = 42)\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Visualizamos el modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "fig = plt.figure(figsize=(15,15))\n",
                "\n",
                "tree.plot_tree(model, feature_names = list(X_train.columns), class_names = [\"0\", \"1\"], filled = True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos el ajuste: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tenemos  unaccuracy del 66,23% vamos a intentar mejorarlo eliminando las variables menos correlacionadas (SkinThickness, DiabetesPedigreeFunction e Insulin)\n",
                "\n",
                "Primero guardamos el modelo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Guardamos el modelo:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "dump(model, open(\"random_forest_def_42.sav\", \"wb\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nuevo dataset sin las variables seleccionadas:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X2=data_clean.drop([\"Outcome\",\"SkinThickness\",\"Insulin\",\"DiabetesPedigreeFunction\"],axis=1,inplace=False).copy()\n",
                "X2.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X2_train,X2_test, y2_train, y2_test= train_test_split(X2,y,train_size=0.2,random_state=42)\n",
                "\n",
                "print(X2_train.info(),y2_train.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model2 = DecisionTreeClassifier(random_state = 42)\n",
                "model2.fit(X2_train, y2_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "fig = plt.figure(figsize=(15,15))\n",
                "\n",
                "tree.plot_tree(model2, feature_names = list(X2_train.columns), class_names = [\"0\", \"1\"], filled = True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y2_pred=model2.predict(X2_test)\n",
                "accuracy_score(y2_pred,y2_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Con la eliminación de estas 3 variables, hemos conseguido un modelo más sencillo y con un accuracy mejor: 67,96%\n",
                "\n",
                "Guardamos el modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pickle import dump\n",
                "\n",
                "dump(model2, open(\"random_forest_2_def_42.sav\", \"wb\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
